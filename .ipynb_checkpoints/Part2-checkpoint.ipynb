{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "import numpy as np\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: string (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.types as tp\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, CountVectorizer\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Data preprocessing\") \\\n",
    "        .config(\"spark.some.config.option\",\"some-value\") \\\n",
    "        .getOrCreate()\n",
    "dataframe = spark.read.csv(\"/home/cse587/Downloads/diccsvs/train.csv\", escape =\"\\\"\", inferSchema = True, header = True)\n",
    "dataframe = dataframe.na.drop(subset=[\"genre\",\"plot\",\"movie_id\"])\n",
    "dataframe.printSchema()\n",
    "df_mapping = spark.read.csv(\"/home/cse587/Downloads/diccsvs/mapping.csv\", escape =\"\\\"\", inferSchema = True, header = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#clean text\n",
    "df_clean = dataframe.select('movie_id', 'movie_name', (lower(regexp_replace('plot',\"[^a-zA-Z\\\\s]\",\"\")).alias('plot')), (lower(regexp_replace(\"genre\",\"[^a-zA-Z\\-/,\\\\s]\",\"\")).alias(\"genre\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def replacelabel(x):\n",
    "    test = x.split(\", \")\n",
    "    num_label = []\n",
    "    if(len(test)<1):\n",
    "        return num_label\n",
    "    for label in test:\n",
    "        if label == 'drama':\n",
    "            num_label.append(0)\n",
    "        elif label == 'comedy':\n",
    "            num_label.append(1)\n",
    "        elif label == 'romance film':\n",
    "            num_label.append(2)\n",
    "        elif label ==  'thriller':\n",
    "            num_label.append(3)\n",
    "        elif label == 'action': \n",
    "            num_label.append(4)\n",
    "        elif label == 'world cinema':\n",
    "            num_label.append(5)\n",
    "        elif label == 'crime fiction':\n",
    "            num_label.append(6)\n",
    "        elif label == 'horror':\n",
    "            num_label.append(7)\n",
    "        elif label == 'black-and-white':\n",
    "            num_label.append(8)\n",
    "        elif label == 'indie':\n",
    "            num_label.append(9)\n",
    "        elif label == 'action/adventure':\n",
    "            num_label.append(10)\n",
    "        elif label == 'adventure':\n",
    "            num_label.append(11)\n",
    "        elif label == 'family film':\n",
    "            num_label.append(12)\n",
    "        elif label == 'short film':\n",
    "            num_label.append(13)\n",
    "        elif label == 'romantic drama':\n",
    "            num_label.append(14)\n",
    "        elif label == 'animation':\n",
    "            num_label.append(15)\n",
    "        elif label == 'musical':\n",
    "            num_label.append(16)\n",
    "        elif label == 'science fiction':\n",
    "            num_label.append(17)\n",
    "        elif label == 'mystery':\n",
    "            num_label.append(18)\n",
    "        elif label == 'romantic comedy':\n",
    "            num_label.append(19)\n",
    "    return num_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_udf = udf(replacelabel, ArrayType(IntegerType()))\n",
    "df_clean = df_clean.withColumn('genre_value',label_udf(df_clean.genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: string (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- genre_value: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Tokenize Plot Text\n",
    "tokenizer = Tokenizer(inputCol = 'plot', outputCol = 'plot_token')\n",
    "df_words_token = tokenizer.transform(df_clean).select(\"movie_id\",\"movie_name\",\"plot_token\",\"genre\",\"genre_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Remove StopWords\n",
    "remover = StopWordsRemover(inputCol = 'plot_token', outputCol = 'plot_clean')\n",
    "df_words_token_rem_stopwor = remover.transform(df_words_token).select(\"movie_id\",\"movie_name\",\"plot_clean\",\"genre\",\"genre_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Text Stemming\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "stem_udf = udf(lambda tokens : [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "df_stemmed = df_words_token_rem_stopwor.withColumn(\"words_stemmed\" ,stem_udf(\"plot_clean\")).select('movie_id',\"words_stemmed\",\"genre\",\"genre_value\")\n",
    "df_stemmed = df_stemmed.withColumnRenamed(\"words_stemmed\",\"plot\")\n",
    "df_stemmed = df_stemmed.withColumnRenamed(\"genre_value\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_stemmed = df_stemmed.withColumn(\"col_0\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_1\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_2\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_3\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_4\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_5\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_6\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_7\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_8\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_9\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_10\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_11\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_12\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_13\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_14\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_15\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_16\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_17\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_18\",lit(0))\n",
    "df_stemmed = df_stemmed.withColumn(\"col_19\",lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_schema = tp.StructType([\n",
    "    tp.StructField(name='movie_id', dataType=tp.StringType(), nullable=True),\n",
    "    tp.StructField(name='plot', dataType=tp.ArrayType(StringType()), nullable=True),\n",
    "    tp.StructField(name='genre', dataType=tp.StringType(), nullable=True),\n",
    "    tp.StructField(name='label', dataType=tp.ArrayType(IntegerType()), nullable=True),\n",
    "    tp.StructField(name='col_0', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_1', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_2', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_3', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_4', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_5', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_6', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_7', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_8', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_9', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_10', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_11', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_12', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_13', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_14', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_15', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_16', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_17', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_18', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='col_19', dataType=tp.IntegerType(), nullable=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_df = df_stemmed.select(\"*\").toPandas()\n",
    "for index, row in result_df.iterrows():\n",
    "    label_arr = row['label']\n",
    "    for i in label_arr:\n",
    "        if i == 0:\n",
    "            result_df.loc[index, \"col_0\"] = 1\n",
    "        if i == 1:\n",
    "            result_df.loc[index, \"col_1\"] = 1\n",
    "        if i == 2:\n",
    "            result_df.loc[index, \"col_2\"] = 1\n",
    "        if i == 3:\n",
    "            result_df.loc[index, \"col_3\"] = 1\n",
    "        if i == 4:\n",
    "            result_df.loc[index, \"col_4\"] = 1\n",
    "        if i == 5:\n",
    "            result_df.loc[index, \"col_5\"] = 1\n",
    "        if i == 6:\n",
    "            result_df.loc[index, \"col_6\"] = 1\n",
    "        if i == 7:\n",
    "            result_df.loc[index, \"col_7\"] = 1\n",
    "        if i == 8:\n",
    "            result_df.loc[index, \"col_8\"] = 1\n",
    "        if i == 9:\n",
    "            result_df.loc[index, \"col_9\"] = 1\n",
    "        if i == 10:\n",
    "            result_df.loc[index, \"col_10\"] = 1\n",
    "        if i == 11:\n",
    "            result_df.loc[index, \"col_11\"] = 1\n",
    "        if i == 12:\n",
    "            result_df.loc[index, \"col_12\"] = 1\n",
    "        if i == 13:\n",
    "            result_df.loc[index, \"col_13\"] = 1\n",
    "        if i == 14:\n",
    "            result_df.loc[index, \"col_14\"] = 1\n",
    "        if i == 15:\n",
    "            result_df.loc[index, \"col_15\"] = 1\n",
    "        if i == 16:\n",
    "            result_df.loc[index, \"col_16\"] = 1\n",
    "        if i == 17:\n",
    "            result_df.loc[index, \"col_17\"] = 1\n",
    "        if i == 18:\n",
    "            result_df.loc[index, \"col_18\"] = 1\n",
    "        if i == 19:\n",
    "            result_df.loc[index, \"col_19\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_stemmed = spark.createDataFrame(result_df, schema = my_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movie_id='23890098', plot=['shlykov', 'hardwork', 'taxi', 'driver', 'lyosha', 'saxophonist', 'develop', 'bizarr', 'loveh', 'relationship', 'despit', 'prejudic', 'realiz', 'arent', 'differ'], genre='world cinema, drama', label=[5, 0], col_0=1, col_1=0, col_2=0, col_3=0, col_4=0, col_5=1, col_6=0, col_7=0, col_8=0, col_9=0, col_10=0, col_11=0, col_12=0, col_13=0, col_14=0, col_15=0, col_16=0, col_17=0, col_18=0, col_19=0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stemmed.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movie_id='23890098', plot=['shlykov', 'hardwork', 'taxi', 'driver', 'lyosha', 'saxophonist', 'develop', 'bizarr', 'loveh', 'relationship', 'despit', 'prejudic', 'realiz', 'arent', 'differ'], genre='world cinema, drama', label=[5, 0], col_0=1, col_1=0, col_2=0, col_3=0, col_4=0, col_5=1, col_6=0, col_7=0, col_8=0, col_9=0, col_10=0, col_11=0, col_12=0, col_13=0, col_14=0, col_15=0, col_16=0, col_17=0, col_18=0, col_19=0, plot_length=['shlykov', 'hardwork', 'taxi', 'driver', 'lyosha', 'saxophonist', 'develop', 'bizarr', 'loveh', 'relationship', 'despit', 'prejudic', 'realiz', 'arent', 'differ'])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter words whose length is greater than 0\n",
    "filter_length_udf = udf(lambda row: [x for x in row if len(x) > 0], ArrayType(StringType()))\n",
    "df_stemmed = df_stemmed.withColumn('plot_length', filter_length_udf(col('plot')))\n",
    "data = df_stemmed.select(\"*\")\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TF = HashingTF(inputCol = 'plot_length', outputCol=\"rawFeatures\")\n",
    "idf = IDF(inputCol = 'rawFeatures', outputCol=\"features\", minDocFreq=1200)\n",
    "pipeline = Pipeline(stages=[TF, idf])\n",
    "pipefit = pipeline.fit(data)\n",
    "trainingData = pipefit.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, OneVsRest\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7009547076408756\n",
      "0.7749525860683404\n",
      "0.8517792278761773\n",
      "0.8576296248674017\n",
      "0.8732842585746889\n",
      "0.8690411135041306\n",
      "0.9029219839917708\n",
      "0.9279951139541611\n",
      "0.9053971519495966\n",
      "0.906136487833103\n",
      "0.9182230222765116\n",
      "0.9272557780706548\n",
      "0.9306631521424669\n",
      "0.9390530071683436\n",
      "0.9350991674435051\n",
      "0.950110900382526\n",
      "0.9422675110096757\n",
      "0.9544504805683243\n",
      "0.9511716866501655\n",
      "0.9508823813044457\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_0', fitIntercept = True)\n",
    "lrModel = lr.fit(trainingData)\n",
    "print(lrModel.summary.accuracy)\n",
    "\n",
    "lr1 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_1', fitIntercept = True)\n",
    "lrModel1 = lr1.fit(trainingData)\n",
    "print(lrModel1.summary.accuracy)\n",
    "\n",
    "lr2 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_2', fitIntercept = True)\n",
    "lrModel2 = lr2.fit(trainingData)\n",
    "print(lrModel2.summary.accuracy)\n",
    "\n",
    "lr3 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_3', fitIntercept = True)\n",
    "lrModel3 = lr3.fit(trainingData)\n",
    "print(lrModel3.summary.accuracy)\n",
    "\n",
    "lr4 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_4', fitIntercept = True)\n",
    "lrModel4 = lr4.fit(trainingData)\n",
    "print(lrModel4.summary.accuracy)\n",
    "\n",
    "lr5 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_5', fitIntercept = True)\n",
    "lrModel5 = lr5.fit(trainingData)\n",
    "print(lrModel5.summary.accuracy)\n",
    "\n",
    "lr6 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_6', fitIntercept = True)\n",
    "lrModel6 = lr6.fit(trainingData)\n",
    "print(lrModel6.summary.accuracy)\n",
    "\n",
    "lr7 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_7', fitIntercept = True)\n",
    "lrModel7 = lr7.fit(trainingData)\n",
    "print(lrModel7.summary.accuracy)\n",
    "\n",
    "lr8 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_8', fitIntercept = True)\n",
    "lrModel8 = lr8.fit(trainingData)\n",
    "print(lrModel8.summary.accuracy)\n",
    "\n",
    "lr9 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_9', fitIntercept = True)\n",
    "lrModel9 = lr9.fit(trainingData)\n",
    "print(lrModel9.summary.accuracy)\n",
    "\n",
    "lr10 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_10', fitIntercept = True)\n",
    "lrModel10 = lr10.fit(trainingData)\n",
    "print(lrModel10.summary.accuracy)\n",
    "\n",
    "lr11 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_11', fitIntercept = True)\n",
    "lrModel11 = lr11.fit(trainingData)\n",
    "print(lrModel11.summary.accuracy)\n",
    "\n",
    "lr12 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_12', fitIntercept = True)\n",
    "lrModel12 = lr12.fit(trainingData)\n",
    "print(lrModel12.summary.accuracy)\n",
    "\n",
    "lr13 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_13', fitIntercept = True)\n",
    "lrModel13 = lr13.fit(trainingData)\n",
    "print(lrModel13.summary.accuracy)\n",
    "\n",
    "lr14 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_14', fitIntercept = True)\n",
    "lrModel14 = lr14.fit(trainingData)\n",
    "print(lrModel14.summary.accuracy)\n",
    "\n",
    "lr15 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_15', fitIntercept = True)\n",
    "lrModel15 = lr15.fit(trainingData)\n",
    "print(lrModel15.summary.accuracy)\n",
    "\n",
    "lr16 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_16', fitIntercept = True)\n",
    "lrModel16 = lr16.fit(trainingData)\n",
    "print(lrModel16.summary.accuracy)\n",
    "\n",
    "lr17 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_17', fitIntercept = True)\n",
    "lrModel17 = lr17.fit(trainingData)\n",
    "print(lrModel17.summary.accuracy)\n",
    "\n",
    "lr18 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_18', fitIntercept = True)\n",
    "lrModel18 = lr18.fit(trainingData)\n",
    "print(lrModel18.summary.accuracy)\n",
    "\n",
    "lr19 = LogisticRegression(maxIter=20, elasticNetParam = 0.1, featuresCol = 'features', labelCol='col_19', fitIntercept = True)\n",
    "lrModel19 = lr19.fit(trainingData)\n",
    "print(lrModel19.summary.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = spark.read.csv(\"/home/cse587/Downloads/diccsvs/test.csv\", escape =\"\\\"\", inferSchema = True, header = True)\n",
    "test_df = test_df.na.drop(subset=[\"plot\",\"movie_id\"])\n",
    "test_df.printSchema()\n",
    "\n",
    "#clean text\n",
    "test_df_clean = test_df.select('movie_id', 'movie_name', (lower(regexp_replace('plot',\"[^a-zA-Z\\\\s]\",\"\")).alias('plot')))\n",
    "\n",
    "#Tokenize Plot Text\n",
    "test_df_words_token = tokenizer.transform(test_df_clean).select(\"movie_id\",\"movie_name\",\"plot_token\")\n",
    "\n",
    "#Remove StopWords\n",
    "test_df_words_token_rem_stopwor = remover.transform(test_df_words_token).select(\"movie_id\",\"movie_name\",\"plot_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Text Stemming\n",
    "test_df_stemmed = test_df_words_token_rem_stopwor.withColumn(\"words_stemmed\" ,stem_udf(\"plot_clean\")).select('movie_id',\"words_stemmed\")\n",
    "test_df_stemmed = test_df_stemmed.withColumnRenamed(\"words_stemmed\",\"plot\")\n",
    "\n",
    "test_df_stemmed = test_df_stemmed.withColumn('plot_length', filter_length_udf(col('plot')))\n",
    "test_data = test_df_stemmed.select(\"movie_id\",\"plot\",\"plot_length\")\n",
    "#test_data.select('plot','plot_length').head(1)\n",
    "test_data = test_df_stemmed.select(\"movie_id\",\"plot\",\"plot_length\")\n",
    "#TF-IDF\n",
    "test_cv_result = pipefit.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movie_id=1335380, plot=['film', 'base', 'event', 'happen', 'ship', 'exodus', '', 'well', 'event', 'deal', 'found', 'state', 'israel', '', 'nurs', 'katherin', 'kitti', 'fremont', '', 'american', 'volunt', 'karaolo', 'intern', 'camp', 'cyprus', 'thousand', 'jew', '', 'holocaust', 'survivor', '', 'held', 'british', 'wont', 'let', 'go', 'palestin', 'anxious', 'wait', 'day', 'liber', 'ari', 'ben', 'canaan', '', 'hagannah', 'rebel', 'previous', 'captain', 'jewish', 'brigad', 'british', 'armi', 'second', 'world', 'war', 'obtain', 'cargo', 'ship', 'smuggl', '', 'jewish', 'inmat', 'camp', 'illeg', 'voyag', 'mandat', 'palestin', 'discov', 'militari', 'author', 'british', 'find', 'refuge', 'ship', 'harbor', 'famagusta', 'blockad', 'refuge', 'stage', 'hunger', 'strike', 'camp', 'doctor', 'die', 'ari', 'threaten', 'blow', 'ship', 'refuge', 'british', 'relent', 'allow', 'exodus', 'safe', 'passag', 'meanwhil', 'kitti', 'grown', 'fond', 'karen', 'hansen', '', 'young', 'danishjewish', 'girl', 'search', 'father', 'separ', 'war', 'taken', 'zionist', 'caus', 'much', 'chagrin', 'kitti', 'hope', 'take', 'young', 'karen', 'america', 'begin', 'new', 'life', 'time', 'opposit', 'partit', 'palestin', 'arab', 'jewish', 'state', 'heat', 'karen', 'young', 'beau', 'dov', 'landau', '', 'proclaim', 'desir', 'join', 'irgun', 'radic', 'zionist', 'underground', 'network', 'dov', 'goe', 'irgun', 'address', 'get', 'caught', 'polic', 'trap', 'freed', 'contact', 'member', 'irgun', 'interview', 'ari', 'ben', 'canaan', 'uncl', 'akiva', '', 'swear', 'dov', 'akiva', 'forc', 'boy', 'confess', 'sonderkommando', 'auschwitz', 'rape', 'nazi', 'due', 'activ', 'akiva', 'disown', 'ari', 'father', 'barak', '', 'head', 'mainstream', 'jewish', 'agenc', 'tri', 'creat', 'jewish', 'state', 'polit', 'diplomat', 'mean', 'fear', 'irgun', 'damag', 'effort', 'especi', 'sinc', 'british', 'put', 'price', 'akiva', 'head', 'dov', 'success', 'bomb', 'king', 'david', 'hotel', 'act', 'terror', 'lead', 'dozen', 'fatal', 'akiva', 'arrest', 'sentenc', 'hang', 'meanwhil', 'karen', 'father', 'found', 'ill', 'hospit', 'jerusalem', 'recogn', 'karen', 'gone', 'live', 'gan', 'dafna', 'fiction', 'jewish', 'kibbutz', 'near', 'mount', 'tabor', 'ari', 'rais', 'actual', 'kibbutz', 'name', 'dafna', 'locat', 'near', 'present', 'lebanes', 'border', 'kitti', 'ari', 'fallen', 'love', 'uncl', 'akiva', 'imprison', 'obstacl', 'ari', 'must', 'devis', 'plan', 'free', 'prison', 'dov', 'landau', 'manag', 'elud', 'arrest', 'soldier', 'turn', 'use', 'knowledg', 'explos', 'rig', 'acr', 'prison', 'plan', 'escap', 'rout', 'goe', 'accord', 'plan', 'hundr', 'prison', 'includ', 'akiva', 'manag', 'escap', 'histor', 'incid', 'base', 'see', 'acr', 'prison', 'break', 'akiva', 'fatal', 'shot', 'british', 'soldier', 'evad', 'roadblock', 'set', 'catch', 'escap', 'prison', 'ari', 'also', 'bad', 'wound', 'make', 'way', 'abu', 'yesha', 'arab', 'villag', 'near', 'gan', 'dafna', 'lifelong', 'friend', 'taha', '', 'mukhtar', 'kitti', 'brought', 'treat', 'wound', 'independ', 'israel', 'plain', 'view', 'arab', 'nation', 'command', 'mohammad', 'amin', 'alhusayni', 'grand', 'mufti', 'jerusalem', 'plot', 'attack', 'gan', 'dafna', 'kill', 'villag', 'ari', 'receiv', 'prior', 'warn', 'attack', 'taha', 'manag', 'get', 'younger', 'children', 'town', 'mass', 'overnight', 'escap', 'karen', 'ecstat', 'prospect', 'new', 'nation', 'find', 'dov', '', 'proclaim', 'love', 'dov', 'assur', 'marri', 'someday', 'karen', 'return', 'gan', 'dafna', 'ambush', 'kill', 'gang', 'arab', 'militiamen', 'dov', 'discov', 'lifeless', 'bodi', 'follow', 'morn', 'day', 'bodi', 'taha', 'found', 'hang', 'villag', 'kill', 'arab', 'extremist', 'star', 'david', 'symbol', 'carv', 'bodi', 'karen', 'taha', 'buri', 'togeth', 'one', 'grave', 'jewish', 'burial', 'ceremoni', 'ari', 'swear', 'bodi', 'someday', 'jew', 'arab', 'live', 'togeth', 'share', 'land', 'peac', 'death', 'also', 'life', 'movi', 'end', 'ari', 'kitti', 'palmach', 'conting', 'enter', 'truck', 'head', 'toward', 'battl'], plot_length=['film', 'base', 'event', 'happen', 'ship', 'exodus', 'well', 'event', 'deal', 'found', 'state', 'israel', 'nurs', 'katherin', 'kitti', 'fremont', 'american', 'volunt', 'karaolo', 'intern', 'camp', 'cyprus', 'thousand', 'jew', 'holocaust', 'survivor', 'held', 'british', 'wont', 'let', 'go', 'palestin', 'anxious', 'wait', 'day', 'liber', 'ari', 'ben', 'canaan', 'hagannah', 'rebel', 'previous', 'captain', 'jewish', 'brigad', 'british', 'armi', 'second', 'world', 'war', 'obtain', 'cargo', 'ship', 'smuggl', 'jewish', 'inmat', 'camp', 'illeg', 'voyag', 'mandat', 'palestin', 'discov', 'militari', 'author', 'british', 'find', 'refuge', 'ship', 'harbor', 'famagusta', 'blockad', 'refuge', 'stage', 'hunger', 'strike', 'camp', 'doctor', 'die', 'ari', 'threaten', 'blow', 'ship', 'refuge', 'british', 'relent', 'allow', 'exodus', 'safe', 'passag', 'meanwhil', 'kitti', 'grown', 'fond', 'karen', 'hansen', 'young', 'danishjewish', 'girl', 'search', 'father', 'separ', 'war', 'taken', 'zionist', 'caus', 'much', 'chagrin', 'kitti', 'hope', 'take', 'young', 'karen', 'america', 'begin', 'new', 'life', 'time', 'opposit', 'partit', 'palestin', 'arab', 'jewish', 'state', 'heat', 'karen', 'young', 'beau', 'dov', 'landau', 'proclaim', 'desir', 'join', 'irgun', 'radic', 'zionist', 'underground', 'network', 'dov', 'goe', 'irgun', 'address', 'get', 'caught', 'polic', 'trap', 'freed', 'contact', 'member', 'irgun', 'interview', 'ari', 'ben', 'canaan', 'uncl', 'akiva', 'swear', 'dov', 'akiva', 'forc', 'boy', 'confess', 'sonderkommando', 'auschwitz', 'rape', 'nazi', 'due', 'activ', 'akiva', 'disown', 'ari', 'father', 'barak', 'head', 'mainstream', 'jewish', 'agenc', 'tri', 'creat', 'jewish', 'state', 'polit', 'diplomat', 'mean', 'fear', 'irgun', 'damag', 'effort', 'especi', 'sinc', 'british', 'put', 'price', 'akiva', 'head', 'dov', 'success', 'bomb', 'king', 'david', 'hotel', 'act', 'terror', 'lead', 'dozen', 'fatal', 'akiva', 'arrest', 'sentenc', 'hang', 'meanwhil', 'karen', 'father', 'found', 'ill', 'hospit', 'jerusalem', 'recogn', 'karen', 'gone', 'live', 'gan', 'dafna', 'fiction', 'jewish', 'kibbutz', 'near', 'mount', 'tabor', 'ari', 'rais', 'actual', 'kibbutz', 'name', 'dafna', 'locat', 'near', 'present', 'lebanes', 'border', 'kitti', 'ari', 'fallen', 'love', 'uncl', 'akiva', 'imprison', 'obstacl', 'ari', 'must', 'devis', 'plan', 'free', 'prison', 'dov', 'landau', 'manag', 'elud', 'arrest', 'soldier', 'turn', 'use', 'knowledg', 'explos', 'rig', 'acr', 'prison', 'plan', 'escap', 'rout', 'goe', 'accord', 'plan', 'hundr', 'prison', 'includ', 'akiva', 'manag', 'escap', 'histor', 'incid', 'base', 'see', 'acr', 'prison', 'break', 'akiva', 'fatal', 'shot', 'british', 'soldier', 'evad', 'roadblock', 'set', 'catch', 'escap', 'prison', 'ari', 'also', 'bad', 'wound', 'make', 'way', 'abu', 'yesha', 'arab', 'villag', 'near', 'gan', 'dafna', 'lifelong', 'friend', 'taha', 'mukhtar', 'kitti', 'brought', 'treat', 'wound', 'independ', 'israel', 'plain', 'view', 'arab', 'nation', 'command', 'mohammad', 'amin', 'alhusayni', 'grand', 'mufti', 'jerusalem', 'plot', 'attack', 'gan', 'dafna', 'kill', 'villag', 'ari', 'receiv', 'prior', 'warn', 'attack', 'taha', 'manag', 'get', 'younger', 'children', 'town', 'mass', 'overnight', 'escap', 'karen', 'ecstat', 'prospect', 'new', 'nation', 'find', 'dov', 'proclaim', 'love', 'dov', 'assur', 'marri', 'someday', 'karen', 'return', 'gan', 'dafna', 'ambush', 'kill', 'gang', 'arab', 'militiamen', 'dov', 'discov', 'lifeless', 'bodi', 'follow', 'morn', 'day', 'bodi', 'taha', 'found', 'hang', 'villag', 'kill', 'arab', 'extremist', 'star', 'david', 'symbol', 'carv', 'bodi', 'karen', 'taha', 'buri', 'togeth', 'one', 'grave', 'jewish', 'burial', 'ceremoni', 'ari', 'swear', 'bodi', 'someday', 'jew', 'arab', 'live', 'togeth', 'share', 'land', 'peac', 'death', 'also', 'life', 'movi', 'end', 'ari', 'kitti', 'palmach', 'conting', 'enter', 'truck', 'head', 'toward', 'battl'], rawFeatures=SparseVector(262144, {2089: 1.0, 3148: 1.0, 4954: 2.0, 5595: 1.0, 5730: 2.0, 6834: 1.0, 7103: 1.0, 9303: 2.0, 9942: 4.0, 9988: 1.0, 11018: 1.0, 13114: 1.0, 13340: 1.0, 13781: 1.0, 13938: 6.0, 13957: 2.0, 14934: 1.0, 17291: 1.0, 18748: 1.0, 18865: 1.0, 19859: 1.0, 20156: 2.0, 22529: 1.0, 22686: 1.0, 22687: 1.0, 23385: 1.0, 23574: 1.0, 23722: 1.0, 24145: 1.0, 24167: 1.0, 26868: 1.0, 28383: 1.0, 29945: 2.0, 30545: 1.0, 30905: 1.0, 33053: 2.0, 33909: 1.0, 34102: 1.0, 35119: 1.0, 36543: 1.0, 38765: 1.0, 43838: 4.0, 44600: 1.0, 45651: 2.0, 45786: 1.0, 45885: 1.0, 46561: 1.0, 46973: 1.0, 54105: 1.0, 55216: 1.0, 55639: 1.0, 58546: 1.0, 60148: 1.0, 62034: 1.0, 62606: 4.0, 63254: 2.0, 64188: 1.0, 64652: 1.0, 65479: 1.0, 65646: 1.0, 66053: 1.0, 71002: 3.0, 71198: 1.0, 71912: 1.0, 72090: 1.0, 73459: 1.0, 74235: 1.0, 75042: 1.0, 75173: 3.0, 75648: 1.0, 76764: 1.0, 78201: 1.0, 78295: 7.0, 79649: 1.0, 80242: 1.0, 80692: 11.0, 82321: 1.0, 85516: 2.0, 86508: 1.0, 86807: 1.0, 87603: 1.0, 88302: 1.0, 88813: 1.0, 89566: 2.0, 89717: 1.0, 90524: 1.0, 90652: 1.0, 91878: 2.0, 92288: 5.0, 93471: 3.0, 93484: 1.0, 94589: 1.0, 94674: 1.0, 96638: 1.0, 96822: 1.0, 97622: 1.0, 98066: 2.0, 98520: 1.0, 99179: 1.0, 99895: 2.0, 100406: 2.0, 100987: 1.0, 101160: 3.0, 101220: 1.0, 101369: 1.0, 103034: 1.0, 103376: 1.0, 104945: 1.0, 105535: 1.0, 105923: 1.0, 107519: 2.0, 108540: 2.0, 109320: 1.0, 109772: 1.0, 110286: 1.0, 111561: 1.0, 111685: 1.0, 112349: 1.0, 113351: 1.0, 114325: 1.0, 114897: 1.0, 115401: 1.0, 116873: 1.0, 116946: 1.0, 119005: 1.0, 119725: 3.0, 120401: 1.0, 120656: 2.0, 120730: 1.0, 121517: 1.0, 122289: 1.0, 124643: 3.0, 125312: 1.0, 125372: 1.0, 125636: 1.0, 128160: 1.0, 128358: 1.0, 129914: 1.0, 130698: 1.0, 131709: 1.0, 132173: 1.0, 133727: 1.0, 134068: 1.0, 134995: 1.0, 135533: 1.0, 138078: 1.0, 138836: 1.0, 139595: 1.0, 139953: 1.0, 141091: 1.0, 141619: 1.0, 142563: 1.0, 147136: 2.0, 148782: 1.0, 148851: 1.0, 149076: 2.0, 149196: 1.0, 149384: 2.0, 149973: 1.0, 150069: 1.0, 150278: 3.0, 150611: 1.0, 152228: 1.0, 152715: 1.0, 153072: 1.0, 154017: 1.0, 154218: 1.0, 157666: 1.0, 158870: 1.0, 159139: 1.0, 160216: 1.0, 160913: 2.0, 163537: 1.0, 164771: 1.0, 165865: 1.0, 167179: 1.0, 169020: 1.0, 170946: 1.0, 171113: 1.0, 172477: 1.0, 172517: 2.0, 173627: 1.0, 174495: 1.0, 174611: 1.0, 175424: 1.0, 175817: 1.0, 175918: 6.0, 178026: 1.0, 181726: 1.0, 181938: 1.0, 182367: 1.0, 182496: 1.0, 183948: 1.0, 184864: 1.0, 185203: 1.0, 185228: 1.0, 185824: 1.0, 186480: 2.0, 186925: 1.0, 187399: 2.0, 187925: 1.0, 188479: 1.0, 189503: 1.0, 190372: 2.0, 191109: 1.0, 191316: 4.0, 191591: 1.0, 191637: 1.0, 192362: 4.0, 195421: 2.0, 195578: 1.0, 198345: 1.0, 198468: 1.0, 199255: 1.0, 200954: 1.0, 201114: 1.0, 202234: 8.0, 202921: 1.0, 204137: 1.0, 204606: 1.0, 206453: 1.0, 206910: 1.0, 208704: 1.0, 209303: 1.0, 210182: 6.0, 210238: 1.0, 210907: 2.0, 211324: 2.0, 212456: 1.0, 213314: 1.0, 214118: 1.0, 214269: 1.0, 215264: 1.0, 215995: 1.0, 216462: 1.0, 218117: 3.0, 219045: 4.0, 221165: 1.0, 221690: 1.0, 222484: 1.0, 224260: 2.0, 226055: 1.0, 226654: 1.0, 226939: 1.0, 227892: 1.0, 228179: 1.0, 228328: 1.0, 228773: 1.0, 229407: 1.0, 229943: 2.0, 230601: 2.0, 230616: 2.0, 230669: 1.0, 230798: 1.0, 232051: 1.0, 232427: 3.0, 232645: 1.0, 234280: 3.0, 235240: 1.0, 237337: 1.0, 237761: 1.0, 238625: 1.0, 238841: 5.0, 239681: 2.0, 239774: 1.0, 240416: 1.0, 240618: 2.0, 240867: 3.0, 242249: 1.0, 244212: 1.0, 247132: 3.0, 247989: 1.0, 248168: 8.0, 248292: 1.0, 249130: 3.0, 250010: 8.0, 250537: 1.0, 250719: 2.0, 253559: 1.0, 255156: 1.0, 255356: 1.0, 255902: 1.0, 256632: 1.0, 258215: 2.0, 260525: 1.0}), features=SparseVector(262144, {2089: 0.0, 3148: 0.0, 4954: 0.0, 5595: 1.7091, 5730: 0.0, 6834: 0.0, 7103: 0.0, 9303: 0.0, 9942: 9.1847, 9988: 0.0, 11018: 3.251, 13114: 0.0, 13340: 0.0, 13781: 1.7711, 13938: 0.0, 13957: 2.7285, 14934: 2.8514, 17291: 1.1765, 18748: 2.3413, 18865: 0.0, 19859: 3.0771, 20156: 0.0, 22529: 0.0, 22686: 0.0, 22687: 0.0, 23385: 2.9795, 23574: 0.0, 23722: 2.1672, 24145: 2.6226, 24167: 2.4409, 26868: 2.1392, 28383: 0.0, 29945: 2.6746, 30545: 2.6852, 30905: 2.4413, 33053: 2.6554, 33909: 2.6288, 34102: 0.0, 35119: 1.4753, 36543: 0.0, 38765: 2.9601, 43838: 6.5918, 44600: 0.0, 45651: 5.2684, 45786: 0.0, 45885: 2.4979, 46561: 0.0, 46973: 2.56, 54105: 0.0, 55216: 0.0, 55639: 0.9061, 58546: 0.0, 60148: 0.0, 62034: 0.0, 62606: 12.3306, 63254: 4.8073, 64188: 2.4183, 64652: 0.0, 65479: 0.0, 65646: 0.0, 66053: 0.0, 71002: 4.3033, 71198: 3.1875, 71912: 0.0, 72090: 0.0, 73459: 0.0, 74235: 0.0, 75042: 2.1198, 75173: 0.0, 75648: 0.0, 76764: 2.2076, 78201: 0.0, 78295: 0.0, 79649: 0.0, 80242: 0.0, 80692: 0.0, 82321: 2.2819, 85516: 0.0, 86508: 3.2313, 86807: 0.0, 87603: 0.0, 88302: 1.5133, 88813: 0.0, 89566: 0.0, 89717: 1.1517, 90524: 1.6882, 90652: 0.0, 91878: 1.7969, 92288: 0.0, 93471: 8.1767, 93484: 2.084, 94589: 0.0, 94674: 0.0, 96638: 2.8935, 96822: 1.2773, 97622: 0.0, 98066: 4.7846, 98520: 0.0, 99179: 2.2082, 99895: 1.9174, 100406: 0.0, 100987: 0.0, 101160: 5.5986, 101220: 0.0, 101369: 0.0, 103034: 3.1629, 103376: 1.6232, 104945: 0.0, 105535: 2.7494, 105923: 0.0, 107519: 3.6375, 108540: 0.0, 109320: 0.0, 109772: 0.0, 110286: 2.6288, 111561: 0.0, 111685: 0.0, 112349: 0.0, 113351: 2.8768, 114325: 0.0, 114897: 0.0, 115401: 2.4201, 116873: 1.4759, 116946: 2.3825, 119005: 0.0, 119725: 5.8231, 120401: 0.0, 120656: 0.0, 120730: 0.0, 121517: 1.2076, 122289: 0.0, 124643: 6.8914, 125312: 0.0, 125372: 0.8689, 125636: 0.0, 128160: 2.4216, 128358: 0.0, 129914: 0.0, 130698: 3.1434, 131709: 3.0083, 132173: 2.5366, 133727: 0.0, 134068: 0.0, 134995: 2.8762, 135533: 1.6878, 138078: 2.2857, 138836: 2.6683, 139595: 0.0, 139953: 1.705, 141091: 2.6346, 141619: 0.0, 142563: 0.0, 147136: 2.6592, 148782: 0.0, 148851: 0.0, 149076: 0.0, 149196: 0.0, 149384: 6.4692, 149973: 2.4029, 150069: 2.5455, 150278: 7.3946, 150611: 0.0, 152228: 0.0, 152715: 1.1233, 153072: 0.0, 154017: 0.0, 154218: 0.0, 157666: 0.0, 158870: 1.2072, 159139: 0.0, 160216: 0.0, 160913: 3.0184, 163537: 0.0, 164771: 2.8365, 165865: 2.6819, 167179: 2.1811, 169020: 0.0, 170946: 0.0, 171113: 0.0, 172477: 1.2917, 172517: 2.5627, 173627: 1.8024, 174495: 3.1844, 174611: 0.0, 175424: 0.0, 175817: 3.0557, 175918: 0.0, 178026: 0.0, 181726: 2.0638, 181938: 2.4461, 182367: 0.0, 182496: 3.1154, 183948: 0.0, 184864: 0.0, 185203: 0.0, 185228: 1.8955, 185824: 0.0, 186480: 2.5034, 186925: 2.0243, 187399: 0.0, 187925: 0.0, 188479: 3.0982, 189503: 2.4801, 190372: 0.0, 191109: 3.057, 191316: 0.0, 191591: 0.0, 191637: 0.0, 192362: 0.0, 195421: 5.7661, 195578: 2.9508, 198345: 0.0, 198468: 0.0, 199255: 1.5259, 200954: 1.7415, 201114: 0.0, 202234: 0.0, 202921: 2.779, 204137: 0.0, 204606: 2.8229, 206453: 0.0, 206910: 0.0, 208704: 0.0, 209303: 0.0, 210182: 0.0, 210238: 0.0, 210907: 5.723, 211324: 0.0, 212456: 0.0, 213314: 2.8865, 214118: 0.0, 214269: 2.5513, 215264: 0.0, 215995: 1.3512, 216462: 2.4443, 218117: 6.7236, 219045: 0.0, 221165: 0.0, 221690: 0.0, 222484: 0.0, 224260: 0.0, 226055: 1.3732, 226654: 0.0, 226939: 2.7878, 227892: 0.0, 228179: 2.548, 228328: 0.0, 228773: 0.0, 229407: 2.2509, 229943: 0.0, 230601: 0.0, 230616: 6.195, 230669: 0.0, 230798: 0.0, 232051: 2.0297, 232427: 5.2263, 232645: 0.0, 234280: 4.4912, 235240: 2.2681, 237337: 2.8223, 237761: 2.6423, 238625: 2.3406, 238841: 12.9863, 239681: 3.1232, 239774: 0.0, 240416: 3.13, 240618: 3.8888, 240867: 0.0, 242249: 0.0, 244212: 0.0, 247132: 0.0, 247989: 0.0, 248168: 0.0, 248292: 3.2453, 249130: 3.7376, 250010: 0.0, 250537: 0.0, 250719: 3.91, 253559: 0.0, 255156: 2.6946, 255356: 1.24, 255902: 0.0, 256632: 0.0, 258215: 0.0, 260525: 1.9605}))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cv_result.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>MODEL LOADING<<<<<<\n",
    "'''from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "savePath = './Part2/LGModel2'\n",
    "lrModel = LogisticRegressionModel.load(savePath + '-1')\n",
    "lrModel2 = LogisticRegressionModel.load(savePath + '-2')\n",
    "lrModel3 = LogisticRegressionModel.load(savePath + '-3')\n",
    "lrModel4 = LogisticRegressionModel.load(savePath + '-4')\n",
    "lrModel5 = LogisticRegressionModel.load(savePath + '-5')\n",
    "lrModel6 = LogisticRegressionModel.load(savePath + '-6')\n",
    "lrModel7 = LogisticRegressionModel.load(savePath + '-7')\n",
    "lrModel8 = LogisticRegressionModel.load(savePath + '-8')\n",
    "lrModel9 = LogisticRegressionModel.load(savePath + '-9')\n",
    "lrModel10 = LogisticRegressionModel.load(savePath + '-10')\n",
    "lrModel11 = LogisticRegressionModel.load(savePath + '-11')\n",
    "lrModel12 = LogisticRegressionModel.load(savePath + '-12')\n",
    "lrModel13 = LogisticRegressionModel.load(savePath + '-13')\n",
    "lrModel14 = LogisticRegressionModel.load(savePath + '-14')\n",
    "lrModel15 = LogisticRegressionModel.load(savePath + '-15')\n",
    "lrModel16 = LogisticRegressionModel.load(savePath + '-16')\n",
    "lrModel17 = LogisticRegressionModel.load(savePath + '-17')\n",
    "lrModel18 = LogisticRegressionModel.load(savePath + '-18')\n",
    "lrModel19 = LogisticRegressionModel.load(savePath + '-19')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = lrModel.transform(test_cv_result)\n",
    "predictions1 = lrModel1.transform(test_cv_result)\n",
    "predictions2 = lrModel2.transform(test_cv_result)\n",
    "predictions3 = lrModel3.transform(test_cv_result)\n",
    "predictions4 = lrModel4.transform(test_cv_result)\n",
    "predictions5 = lrModel5.transform(test_cv_result)\n",
    "predictions6 = lrModel6.transform(test_cv_result)\n",
    "predictions7 = lrModel7.transform(test_cv_result)\n",
    "predictions8 = lrModel8.transform(test_cv_result)\n",
    "predictions9 = lrModel9.transform(test_cv_result)\n",
    "predictions10 = lrModel10.transform(test_cv_result)\n",
    "predictions11 = lrModel11.transform(test_cv_result)\n",
    "predictions12 = lrModel12.transform(test_cv_result)\n",
    "predictions13 = lrModel13.transform(test_cv_result)\n",
    "predictions14 = lrModel14.transform(test_cv_result)\n",
    "predictions15 = lrModel15.transform(test_cv_result)\n",
    "predictions16 = lrModel16.transform(test_cv_result)\n",
    "predictions17 = lrModel17.transform(test_cv_result)\n",
    "predictions18 = lrModel18.transform(test_cv_result)\n",
    "predictions19 = lrModel19.transform(test_cv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction=0.0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions12.select('prediction').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate testing\n"
     ]
    }
   ],
   "source": [
    "dict = {}\n",
    "movie_id = predictions.select(F.collect_list('movie_id')).first()[0]\n",
    "pred1 = predictions.select(F.collect_list('prediction')).first()[0]\n",
    "pred2 = predictions1.select(F.collect_list('prediction')).first()[0]\n",
    "pred3 = predictions2.select(F.collect_list('prediction')).first()[0]\n",
    "pred4 = predictions3.select(F.collect_list('prediction')).first()[0]\n",
    "pred5 = predictions4.select(F.collect_list('prediction')).first()[0]\n",
    "pred6 = predictions5.select(F.collect_list('prediction')).first()[0]\n",
    "pred7 = predictions6.select(F.collect_list('prediction')).first()[0]\n",
    "print(\"intermediate testing\")\n",
    "pred8 = predictions7.select(F.collect_list('prediction')).first()[0]\n",
    "pred9 = predictions8.select(F.collect_list('prediction')).first()[0]\n",
    "pred10 = predictions9.select(F.collect_list('prediction')).first()[0]\n",
    "pred11 = predictions10.select(F.collect_list('prediction')).first()[0]\n",
    "pred12 = predictions11.select(F.collect_list('prediction')).first()[0]\n",
    "pred13 = predictions12.select(F.collect_list('prediction')).first()[0]\n",
    "pred14 = predictions13.select(F.collect_list('prediction')).first()[0]\n",
    "pred15 = predictions14.select(F.collect_list('prediction')).first()[0]\n",
    "pred16 = predictions15.select(F.collect_list('prediction')).first()[0]\n",
    "pred17 = predictions16.select(F.collect_list('prediction')).first()[0]\n",
    "pred18 = predictions17.select(F.collect_list('prediction')).first()[0]\n",
    "pred19 = predictions18.select(F.collect_list('prediction')).first()[0]\n",
    "pred20 = predictions19.select(F.collect_list('prediction')).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from csv import writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def append_list_as_row(filename, elements):\n",
    "    with open(filename, 'a+', newline='') as write_obj:\n",
    "        csv_writer = writer(write_obj)\n",
    "        csv_writer.writerow(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(pred1)):\n",
    "    p = \"\"\n",
    "    p+=str(int(pred1[i]))\n",
    "    p+=\" \"+str(int(pred2[i]))\n",
    "    p+=\" \"+str(int(pred3[i]))\n",
    "    p+=\" \"+str(int(pred4[i]))\n",
    "    p+=\" \"+str(int(pred5[i]))\n",
    "    p+=\" \"+str(int(pred6[i]))\n",
    "    p+=\" \"+str(int(pred7[i]))\n",
    "    p+=\" \"+str(int(pred8[i]))\n",
    "    p+=\" \"+str(int(pred9[i]))\n",
    "    p+=\" \"+str(int(pred10[i]))\n",
    "    p+=\" \"+str(int(pred11[i]))\n",
    "    p+=\" \"+str(int(pred12[i]))\n",
    "    p+=\" \"+str(int(pred13[i]))\n",
    "    p+=\" \"+str(int(pred14[i]))\n",
    "    p+=\" \"+str(int(pred15[i]))\n",
    "    p+=\" \"+str(int(pred16[i]))\n",
    "    p+=\" \"+str(int(pred17[i]))\n",
    "    p+=\" \"+str(int(pred18[i]))\n",
    "    p+=\" \"+str(int(pred19[i]))\n",
    "    p+=\" \"+str(int(pred20[i]))\n",
    "    dict[movie_id[i]] = p\n",
    "    row_contents= [movie_id[i], p]\n",
    "    append_list_as_row(\"/home/cse587/DICNEWFinal/output2.csv\", row_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel.save(\"/home/cse587/DICNEWFinal/LGModel2-1/\")\n",
    "lrModel1.save(\"/home/cse587/DICNEWFinal/LGModel2-2/\")\n",
    "lrModel2.save(\"/home/cse587/DICNEWFinal/LGModel2-3/\")\n",
    "lrModel3.save(\"/home/cse587/DICNEWFinal/LGModel2-4/\")\n",
    "lrModel4.save(\"/home/cse587/DICNEWFinal/LGModel2-5/\")\n",
    "lrModel5.save(\"/home/cse587/DICNEWFinal/LGModel2-6/\")\n",
    "lrModel6.save(\"/home/cse587/DICNEWFinal/LGModel2-7/\")\n",
    "lrModel7.save(\"/home/cse587/DICNEWFinal/LGModel2-8/\")\n",
    "lrModel8.save(\"/home/cse587/DICNEWFinal/LGModel2-9/\")\n",
    "lrModel9.save(\"/home/cse587/DICNEWFinal/LGModel2-10/\")\n",
    "lrModel10.save(\"/home/cse587/DICNEWFinal/LGModel2-11/\")\n",
    "lrModel11.save(\"/home/cse587/DICNEWFinal/LGModel2-12/\")\n",
    "lrModel12.save(\"/home/cse587/DICNEWFinal/LGModel2-13/\")\n",
    "lrModel13.save(\"/home/cse587/DICNEWFinal/LGModel2-14/\")\n",
    "lrModel14.save(\"/home/cse587/DICNEWFinal/LGModel2-15/\")\n",
    "lrModel15.save(\"/home/cse587/DICNEWFinal/LGModel2-16/\")\n",
    "lrModel16.save(\"/home/cse587/DICNEWFinal/LGModel2-17/\")\n",
    "lrModel17.save(\"/home/cse587/DICNEWFinal/LGModel2-18/\")\n",
    "lrModel18.save(\"/home/cse587/DICNEWFinal/LGModel2-19/\")\n",
    "lrModel19.save(\"/home/cse587/DICNEWFinal/LGModel2-20/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
